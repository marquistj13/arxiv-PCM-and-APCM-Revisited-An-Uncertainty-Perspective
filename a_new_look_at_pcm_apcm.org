#+STARTUP: content
#+OPTIONS: 
#+OPTIONS: toc:nil
# set DATE to void to avoid it's display
#+DATE: 
#+LATEX_CLASS: IEEEtran
#+LaTeX_CLASS_OPTIONS: [journal]
#+LATEX_HEADER: \usepackage{subfig}
# bold and italic vector
#+LATEX_HEADER: \newcommand{\vect}[1]{\boldsymbol{#1}}
# In IEEEtran_HOWTO the equations section on page 8. this 2500 config is to estore IEEEtran ability to automatically break within multiline equations
#+LATEX_HEADER: \interdisplaylinepenalty=2500

#+TITLE: A New Look at PCM and APCM

\begin{abstract}
We propose a unified framework for pcm and apcm, from the viewpoint (or by considering?) of uncertainty of the bandwidth parameter. It's shown that the difference between them is how much confidence we have in the data. In fact, the uncertainty of the bandwidth parameter is into the membership of  a point, this is done by using Prof. LiXin Wang's new formulation of the Type 2 fuzzy set, i.e. the conditional fuzzy set framework. Thus this paper also serves as a justify for this new formulation.
\end{abstract}

** PCM and APCM Review and Questions
*** review of pcm and apcm
Typicality is one of the most commonly used interpretations of memberships in applications of fuzzy set theory. The membership value produced by fuzzy c-means (FCM) \cite{bezdek_pattern_2013} can't be used to indicate the typicality of a point in the cluster. Possibilistic c-means (PCM) \cite{krishnapuram_possibilistic_1993} solves this problem by forcing the membership of a point to be small if it's far from the cluster center (prototype). This intuition is incorporated into the objection function by adding a penalty term:
#+BEGIN_LaTeX
\begin{equation}
J(\Theta,U)=\sum_{j=1}^{c}J_j=\sum_{j=1}^{c}\left[\sum_{i=1}^{N}u_{ij}d_{ij}^2+\gamma_j \sum_{i=1}^{N}f(u_{ij})\right]
\end{equation}
#+END_LaTeX
where $\Theta=(\theta_1,\ldots,\theta_c)$ is a $c$-tuple of prototypes, $d_{ij}^2$ is the distance of feature point $x_i$ to prototype $\theta_j$, $N$ is the total number of feature vectors, $c$ is the number of clusters, and $U=[u_{ij}]$ is a $N\times c$ matrix where $u_{ij}$ denotes the /degree of compatibility/ of $x_i$ to the $j$th cluster $C_j$ which is represented by $\theta_j$. $\gamma_j$ can be seen as a bandwidth parameter of the possibility (membership) distribution for each cluster. $f(\cdot)$ is a decreasing function of $u_{ij}$ and forces the $u_{ij}$ as large as possible, thus avoiding the trivial solution that $u_{ij}=0$. A good choice for $f(\cdot)$ is proposed in \cite{krishnapuram_possibilistic_1996}:
#+BEGIN_LaTeX
\begin{equation}
f(u_{ij})=u_{ij}\log u_{ij}-u_{ij}
\end{equation}
#+END_LaTeX 

After minimizing $J(\Theta,U)$ with respect to $u_{ij}$ and $\theta_j$, we get the following update equations:
#+BEGIN_LaTeX
\begin{IEEEeqnarray}{ll}
u_{ij}&=\exp\left(-\frac{d^2_{ij}}{\gamma_j}\right) \label{pcm_u_update}  \\
\theta_j&=\frac{\Sigma_{i=1}^Nu_{ij}x_i}{\Sigma_{i=1}^Nu_{ij}} \label{pcm_theta_update}
\end{IEEEeqnarray}
#+END_LaTeX

In PCM, the clusters do not have a lot of mobility, so a reasonable good initialization is required for the algorithm to converge to the global minimum. A common strategy for initializing is to run the FCM algorithm first and set
#+BEGIN_LaTeX
\begin{equation}
\gamma_j=\frac{\Sigma_{i=1}^Nu_{ij}^{FCM}d^2_{ij}}{\Sigma_{i=1}^Nu_{ij}^{FCM}}
\end{equation}
#+END_LaTeX 
where $d_{ij}=||x_i-\theta_j||$, $\theta_j$s and $u_{ij}^{FCM}$s are the final FCM estimates for cluster prototypes and membership values respectively. Then $\gamma_j$s are fixed and iterations are performed until a specific termination criterion is met.

As pointed out in \cite{krishnapuram_possibilistic_1996}, PCM is primarily a mode-seeking algorithm. In other words, the algorithm can potentially find $c$ dense regions from a data set that may not have $c$ clusters. However, due to the well-known fact that since no link exists among clusters, each $J_j$ can be minimized independently, the $c$ dense regions found may be coincident, as reported in \cite{barni_comments_1996}. It was suggested in \cite{krishnapuram_possibilistic_1996} that this behavior is "a blessing in disguise" and can be utilized by merging coincident clusters after over-specifying $c$. This idea is implemented in the adaptive possibilistic c-means algorithm (APCM) \cite{xenaki_novel_2016} by adapting $\gamma_j$ at each iteration. Cluster $C_j$ is merged with another cluster and is eliminated when there are no points in cluster $C_j$ or $\gamma_j$ becomes $0$. This cluster elimination ability allows us to over-specify the cluster number and the algorithm still produces a reasonable number of clusters, which makes the algorithm very flexible because we don't need to have strong prior knowledge of the cluster number.

However we should prevent the unexpected cluster elimination. In the case where two physical clusters of very different variance that are located very close to each other (see Fig.\ref{fig1_ori}), the prototype of the small variance cluster is affected by the data points of its nearby big cluster which has numerous points, according to (\ref{pcm_u_update}) and (\ref{pcm_theta_update}). As a result, the two prototypes will merge. APCM alleviates this issue by introducing a parameter in $\gamma_j$ to manually scale the bandwidth:
#+BEGIN_LaTeX
\begin{equation}
\label{corrected_eta}
\gamma_j=\frac{\hat{\eta}}{\alpha}\eta_j
\end{equation}
#+END_LaTeX 
where $\hat{\eta}$ is a constant defined as the minimum among all initial $\eta_j$s, $\hat{\eta}=\min_j\eta_j$, and $\alpha$ is chosen so that the quantity $\hat{\eta}/\alpha$ equals to the mean absolute deviation ($\eta_j$)  of the smallest physical cluster formed in the dataset. $\eta_j$ is initialized as
#+BEGIN_LaTeX
\begin{equation}
\label{apcm_eta_init}
\eta_j=\frac{\Sigma_{i=1}^Nu_{ij}^{FCM}d_{ij}}{\Sigma_{i=1}^Nu_{ij}^{FCM}}  
\end{equation}
#+END_LaTeX 
where $d_{ij}=||x_i-\theta_j||$, $\theta_j$s and $u_{ij}^{FCM}$s in \ref{apcm_eta_init} are the final parameter estimates obtained by FCM. $\eta_j$ is updated at each iteration as the /mean absolute deviation/ of the most compatible to cluster $C_j$ data points which form a set $A_j$, i.e., $A_j=\{x_i|u_{ij}=\max_r u_{ir}\}$.
#+BEGIN_LaTeX
\begin{equation}
\label{apcm_eta_update}
\eta_j=\frac{1}{n_j}\sum_{x_i:}||x_i-\mu_j||
\end{equation}
#+END_LaTeX 
where $n_j$ and $\mu_j$ are the number of points in $A_j$ and the mean vector of points in $A_j$ respectively. APCM only allows points in $A_j$ to update $\eta_j$, which is an essential condition for succeeding cluster elimination, as by this way, $\eta_j$ can become $0$. APCM chooses $\mu_j$ and not $\theta_j$ to update $\eta_j$ because $\theta_j$ may vary significantly while $\mu_j$ is more stable during the first few iterations.

*** analysis and questions and motivations
#+BEGIN_LaTeX
\begin{figure*}[!t]
   \centering
   \subfloat[a]
    {\includegraphics[width=1.2in]{img/fig1_ori.png}\label{fig1_ori}}
   \hfil
   \subfloat[b]
    {\includegraphics[width=1.2in]{img/fig1_init.png}\label{fig1_init}}
\end{figure*}
#+END_LaTeX
#+BEGIN_LaTeX
\begin{figure*}[!t]
   \centering
   \subfloat[a]
    {\includegraphics[width=1.2in]{img/fig6_ori.png}\label{fig6_ori}}
   \hfil
   \subfloat[b]
    {\includegraphics[width=1.2in]{img/fig6_init.png}\label{fig6_init}}
\end{figure*}
#+END_LaTeX
Fig.\ref{fig1_ori} and Fig.{fig6_ori} are two typical clustering problems. The two clusters in Fig.\ref{fig1_ori} are generated by normal distributions with centers $c1=[13, 13]^T$, $c2=[5, 0]^T$, covariance matrixes $\Sigma_1=I$, $\Sigma_2=3.7^2I$ respectively, where $I$ is the $2\times 2$ identity matrix. The three clusters in Fig.\ref{fig6_ori} are generated by normal distributions with centers $c1=[1, 0]^T$, $c2=[2.25, 1.5]^T$, $c3=[1.75, 2]^T$ respectively and covariance matrixes are all $\Sigma=0.2^2I$. Fig.\ref{fig1_init} and Fig.{fig6_init} show the initialization results obtained by FCM with 10 clusters.

However, APCM has to deal with these two problems differently. The two physical clusters in Fig.\ref{fig1_ori} are well separated. With the initialization of Fig.\ref{fig1_init}, APCM estimates $\eta_j$ by (\ref{apcm_eta_update}), which is corrected by $\hat{\eta}/\alpha$ and we get the bandwidth $\gamma_j$ by (\ref{corrected_eta}). The only care is that the bandwidth correction term $\hat{\eta}/\alpha$ specified by the user is not too small so that the small initialization clusters of Cluster $1$ have enough mobility \footnote{Large bandwidth means more mobility.  Note that $\hat{\eta}/\alpha$ should also not be too large to avoid the case where all clusters merge into one cluster. This fact can be seen in Fig.7 of \cite{xenaki_novel_2016} when $\alpha$ is small} to merge, according to (\ref{pcm_theta_update}).
As to Fig.\ref{fig6_ori}, Cluster $2$ and Cluster $3$ well separated. The bandwidth correction term $\hat{\eta}/\alpha$ should be not too small so that the small initialization clusters of each physical cluster can merge. The term $\hat{\eta}/\alpha$ should also be too large so that Cluster $2$ and Cluster $3$ don't have enough mobility to merge.
In summary, the choice of $\alpha$ in the correction term  should be dealt with differently.


1. The above analysis shows that there is some difference between the two problems. In fact, the clustering algorithm faces a more noisy environment in Fig.\ref{fig6_ori} than in Fig.\ref{fig1_ori}. This means that we should have more control over the bandwidth correction term in noisy environment.
2. The reason APCM introduces a bandwidth correction term is that the estimated bandwidth is not always reliable to recognize the structure underlying the data set. In other words, there is uncertainty in the estimated bandwidth, this uncertainty causes the uncertainty of the membership value of a point through \ref{pcm_u_update}, then the uncertainty passes to the cluster center through \ref{pcm_theta_update}. If this uncertainty is not properly handled, the clustering algorithm would fail. 
   In APCM, membership values of all points in each cluster are treated equally uncertain, and receive the same bandwidth correction.
   However, we are less confident about the membership value of a point far from the prototype (cluster center) than the membership value of a point near the prototype. So we should have a more flexible bandwidth correction technique.

This paper tries to address the above two needs. Next Section we will use the type-2 fuzzy set to model the uncertainty of a membership value caused by the uncertainty of the estimated bandwidth. next next section, we will show that the two needs are combined, that is the uncertainty specified by the user should be large in noisy environments. We will also show that PCM and APCM are unified in the same framework.

*** the following contents, I haven't decided where to put them
     
1. What is the link between PCM and APCM?
   It seems that the main difference of them is whether $\gamma_j$ varies. Can they be unified in the same framework?
These two questions will be answered in Section.x. The next Section will show how to use type-2 fuzzy set to incorporate the uncertainty of estimated bandwidth into the membership value of point $x_i$.

apcm introduces the concept of smallest physical cluster to cope with the situation where close clusters are equally sized. The unified framework will cope with this situation by noise level.
The main difference(or clustering behavior?) between pcm and apcm is that in apcm we can protect the small cluster from being dragged to the big cluster by manually specifying the bandwidth of the  minimum physical cluster. In this way, if the bandwidth of the small cluster is over-estimated, minimum physical cluster bandwidth will correct it to a lower value, or larger value otherwise.

From formula x, we see that the membership of a point to some cluster is determined by the cluster center and the bandwidth. So we propose that the center update should be modified to avoid being dragged by the large cluster.
** The Conditional Fuzzy Set Framework
In this section, we first review the conditional fuzzy set framework. Then we show through an example that this new definition of a type-2 fuzzy is natural and reasonable to incorporate the uncertainty of the estimated bandwidth.
*** The Conditional Fuzzy Set Framework Review
According to Zadeh \cite{zadeh_concept_1975}, a type-2 fuzzy set (T2 FS) is a fuzzy set whose membership values are type-1 fuzzy set on $[0,1]$. When written in more precise mathematical terms,  this definition becomes as follows \cite{wang_new_2016}:

Definition 1 (type-2 fuzzy sets ): A type-2 fuzzy set $\tilde{X}$ is a fuzzy set defined on the universe of discourse $\Omega_X$ whose membership value $\mu_\tilde{X}(x)$ for a given $x\in\Omega_X$ is a type-1 fuzzy set  $U(x)=\mu_\tilde{X}(x)$ defined on $\Omega_X\subseteq[0,1]$ with membership function \mu_{U(x)}(x,\mu_x) where $\mu_x\in\Omega_X\subseteq[0,1]$. The x is called /primary variable/ and $\mu_x$ is called the /secondary variable/. \qedsymbol

It's clear that T2 FS is just that one fussiness (uncertainty) depends on another fuzziness. However Definition 1 makes T2 FS a complex subject. To simplify this problem, Li-Xin Wang \cite{wang_new_2016} proposes a conditional fuzzy set framework:

Definition 2 (conditional fuzzy sets): Let $X$ and $V$ be fuzzy sets defined on $\Omega_X$ and $\Omega_Y$, respectively. A _conditional fuzzy set_, denoted as $X|V$, is a fuzzy set defined on $\Omega_X$ with membership function:
#+BEGIN_LaTeX
\begin{equation}
\mu_{X|V}(x|V),\;\;\;\;\;\;x\in\Omega_X
\end{equation}
#+END_LaTeX
depending on the fuzzy set $V$ whose membership function is $\mu_V(v)$ with $v\in\Omega_V$. The x is called the /primary variable/ and $v$ is called the /secondary variable/; the membership function $\mu_{X|V}(x|V)$ characterizes the /primary fuzziness/ while the membership function $\mu_V(v)$ characterizes the /secondary fuzziness/.

This framework resembles the concept of conditional probability in probability theory, which studies the dependence of one randomness on the other randomness. It is shown in \cite{wang_new_2016} that the above two definitions are equivalent. However the conditional fuzzy set framework provide a much more natural framework to model the dependence among multiple fuzziness than the type-2 fuzzy set formulation.
In most real-world applications we choose the membership functions to have a fixed structure with some free parameters, such as the Gaussian membership function with the center or standard deviation as free parameters. In such formulations, the uncertainty (fuzziness) of the membership comes from the uncertainties of the free parameters; i.e., the parameter uncertainties are the causes, while the membership uncertainty is the effect, and it is natural to choose the independent cause as the secondary variable to characterize the secondary fuzziness (as in Definition 2 for a conditional fuzzy set), rather than choosing the dependent effect as the secondary variable (as in Definition 1 for a type-2 fuzzy set).

It is also shown in\cite{wang_new_2016} that a conditional fuzzy set $X|V$ is equivalent to a fuzzy relation on $\Omega_X\times\Omega_V$ with membership function:
#+BEGIN_LaTeX
\label{fuzzy_relation}
\begin{equation}
\mu_{X|V}(x,v)=t[\mu_{X|V}(x|v),\mu_V(v)]
\end{equation}
#+END_LaTeX
where $x\in\Omega_X$, $v\in\Omega_V$, $t[*,*]$ is the $t$-norm operator with minimum and product as the most common choices, and $\mu_{X|V}(x,v)$ is the membership function $\mu_{X|V}(x|V)$ of the conditional fuzzy set $X|V$ with the fuzzy set $V$  replaced by a free variable $v\in\Omega_V$

In the study of several random variables, the statistics of each are called marginal, and the probability density function (pdf) of a single random variable is called a marginal pdf. Similarly, since the conditional fuzzy set or the type-2 fuzzy set contains two fuzzy variables (the primary and secondary variables), the concept of marginal fuzzy set for conditional fuzzy sets is introduced in \cite{wang_new_2016} as follows:
Definition 3 (marginal fuzzy sets, Compositional Rule of Inference Scheme): Let $X|V$ be a conditional fuzzy set defined in Definition 2 whoese membership function $\mu_{X|V}(x,v)$ is given by (\ref{fuzzy_relation}). The /marginal fuzzy set/ of $X|V$, denoted as $X$, is a type-1 fuzzy set on $\Omega_X$ whose membership function $\mu_X(x)$ is determined through Zadeh's Compositional Rule of Inference:
#+BEGIN_LaTeX
\label{marginal_fs}
\begin{equation}
\mu_X(x)=\max_{v\in\Omega_V}\min[\mu_{X|V}(x|v),\mu_V(v)],\;\;x\in\Omega_X
\end{equation}
#+END_LaTeX

Then the basic philosophy to dealing with type-2 fuzziness is to use (\ref{marginal_fs}) to "cancel out" the secondary fuzziness $V$ and transform the type-2 problems back to the ordinary type-1 framework. We can explicitly model the uncertainty of the membership caused by some parameter $V$ and "cancel" $V$ to get the type-1 marginal fuzzy set. Then the effect of the uncertainty of $V$ is incorporated into type-1 marginal fuzzy set. 
*** An Example to Illustrate the Incorporation of Uncertainty
Suppose we have estimated the center $x_0$ and bandwidth $v_0$ of a Gaussian membership function $\mu_X{x}$ to represent some cluster, and we want to consider the uncertainty of $\mu_X{x}$ caused by the uncertainty of the bandwidth parameter $V$. First, the conditional fuzzy set $X|V$ is constructed as follows:
#+BEGIN_LaTeX
\begin{equation}
\mu_{X|V}(x|V)=e^{-\frac{|x-x_0|^2}{V^2}}
\end{equation}
#+END_LaTeX
and the uncertainty (fuzziness) of $V$ is also modeled as a Gaussian fuzzy set with the membership function:
#+BEGIN_LaTeX
\begin{equation}
\mu_V(v)=e^{-\frac{(v-v0)^2}{\sigma^2_v}}
\end{equation}
#+END_LaTeX
where $\sigma_v$ is a given constant determining the uncertainty of parameter $V$. Then according to Definition 3 (\ref{marginal_fs}), the marginal fuzzy set $X$ of $X|V$ with membership function:
#+BEGIN_LaTeX
\label{marginal_result}
\begin{IEEEeqnarray}{ll}
\mu_X(x)&=\max_{v\in R_+ }\min\left[e^{-\frac{|x-x_0|^2}{V^2}},e^{-\frac{(v-v0)^2}{\sigma^2_v}}\right] \nonumber \\
        &=e^{-\frac{|x-x_0|^2}{v_{new}}
\end{IEEEeqnarray}
#+END_LaTeX
where $v_{new}=0.5v^2_0+0.5v_0\sqrt{v_0^2+4\sigma_v|x-x_0|}+\sigma_v|x-c|}$. The last line is achieved at the highest point of the intersection $e^{-\frac{|x-x_0|^2}{V^2}}=e^{-\frac{(v-v0)^2}{\sigma^2_v}}$ which gives $v^2=v_{new}$ and substituting it into $e^{-\frac{|x-x_0|^2}{V^2}}$ or $e^{-\frac{(v-v0)^2}{\sigma^2_v}}$ gives the result. Let $d(x_i,x_0)$ denote the distance from a point $x_i$ to the center $x_0$. Then result (\ref{marginal_result}) can be generalized by replacing $|x-c|$ with $d(x_i,x_0)$.
#+BEGIN_LaTeX
\begin{figure*}[!t]
   \centering
   \subfloat[a]
    {\includegraphics[width=1.2in]{img/type2_mf_1_primary.png}\label{primary_fuzziness}}
   \hfil
   \subfloat[b]
    {\includegraphics[width=1.2in]{img/type2_mf_2_secondary.png}\label{secondary_fuzziness}}
   \hfil
   \subfloat[c]
    {\includegraphics[width=1.2in]{img/type2_mf_3_marginal.png}\label{marginal_fuzziness}}
   \label{illustrate_bandwidth_marginal}
\end{figure*}
#+END_LaTeX
Fig.\ref{primary_fuzziness} shows the primary fuzziness when $x_0$ is estimated as 12.5 and $v_0$ is estimated as 2.5 but with uncertainty. Fig.\ref{secondary_fuzziness} shows the secondary fuzziness (uncertainty) of $v_0$ with various $\sigma_v$s. Note that we don't intend to model the uncertainty of $\sigma_v$ here. So we assume $\sigma_v$ is a given value. Fig.\ref{marginal_fuzziness} shows the marginal fuzzy fuzzy set into which the uncertainty has been incorporated.

We can see from (\ref{marginal_result}) and Fig.\ref{marginal_fuzziness} that 
the marginal fuzzy set curve is more flat when the estimated bandwidth has much uncertainty, i.e., $\sigma_v$ is large.
For a specific $\sigma_v$, the corrected bandwidth ($v_new$ in (\ref{marginal_result})) is almost the same as $v_0$ when $d(x_i,x_0)$ is small, and $v_new$ increases as $d(x_i,x_0)$ becomes large.
In other words, the uncertainty of the bandwidth $v_0$ is incorporated into the marginal fuzzy set $\mu_X(x)$ in such a way that membership function of points with small $d(x_i,x_0)$ remains almost the same shape as the one with $\sigma_v=0$ (i.e., with no uncertainty in $v_0$), and membership function of points with large $d(x_i,x_0)$ deviates much from the one with $\sigma_v=0$. The degree of deviation is controlled by $\sigma_v$ and $d(x_i,x_0)$. This behavior is very intuitive in the sense that the uncertainty of bandwidth $v_0$ is obviously reflected in the membership of $x_i$ only when $x_i$ is far from the center and $x_i$ can be seen as a noisy datum in this case. 

(Below is a few open questions. The marginal fuzzy set incorporates uncertainty of the bandwidth by making the membership function curve more flat.  But why not make it more steep? Does the steepness of a membership function curve reflects uncertainty of the bandwidth? If so, small cluster with small bandwidth has less uncertainty than the big cluster? Note that if the curve is very steep, we can be very sure that the membership of point $x_1$ is very different from point $x_2$. But if the curve is less steep, their memberships become similar, we can't easily differentiate them any more. )

From the above analysis, we can conclude that it's reasonable to use the marginal fuzzy set to incorporate the uncertainty of the bandwidth. But it's not easy to specify $\sigma_v$ so that the uncertainty of the bandwidth is properly represented. Next we will show that the choice of $\sigma_v$ depends on noise level of the data set.
** The unified Framework
*** introduce the framework
In the PCM region, the small cluster has too  much mobility, so its prototype moves to the dense region of the whole data set, according to \ref{pcm_theta_update}, note that this is of course not the real dense region, it is just the average of good points in the data set, at the same time the big cluster almost stays in the dense region of the big cluster  . The two cluster may or may not merge. If the small cluster has many points, for example, 400 points, or if we set the noise level to 0.1, both this case has the same effect, that is, makes the estimated whole data set  dense region deviate from the big cluster. (Both cases have corresponding picture?)
In the APCM region, Both clusters stay in their own dense region. That is, we manually confine their bandwidth.
*** Analysis of the parameters
1. 先从最本质的讲起吧。It's too noisy for the smaller cluster in the sense that if all points are used to compute its center (update its center), then the center will be dragged towards the larger cluster because there are more points in the larger cluster. Similarly, the larger cluster is dragged by the smaller cluster in the same way. 
   The $\alpha-\text{cut}$ trick proposed in \cite{krishnapuram_possibilistic_1993} is used to compute the bandwidth with only the "good" feature point , and it's used here to update the center. but if we increase the sigma_v (uncertainty of the bandwidth), its easy to see from the MF figure that the two clusters are in noisy environment again.
2. If the two clusters are closer than in fig.1, then  we have to  specify a larger noise level ( $\alpha$ is large), and the allowed uncertainty of bandwidth is also larger.
   if the noise level is set very high, the bandwidth should be increased in order to search the correct center in dense region and also to enable possible cluster elimination, because a high noise level may indicate that fewer points are actually contributed to the adaption of center.  however the bandwidth shouldn't be too large. ( I have a plot, when bandwidth is not correspondingly increased, an redundant cluster is not eliminated.)
3. this is the way how pcm misses out the smaller cluster. $\alpha$ and sigma_v are used together to constrain each cluster to stay in there clusters ,while still allowing to eliminate clusters in the same dense region.
4. 要先说一下不同noise level下，center 估计误差和 sigma_v的关系。稍微解释一下这个关系
   我初步画图的结果显示，此图正好证实了根据noise level vs 中心估计误差曲线可以判定何时由apcm转化为pcm的。
5. 然后给出一个example来理解这个关系。考多少分能反映一个人的真实水平，if you say that he or she should scores at least 60, you have assumed that the easy degree of the paper is normal. However if the test is very hard, you only need to score say, 30. That is, weather the score would reflect the level of the 考试者 or not depends on the hardness of the test.
6. 引出Type3 FS的必要性。但beyond our scope,因此留给读者来解决。
   Similarly  .for summarize, We can be sure that the uncertainty of bandwidth ( sigma_v ) depends on the noise level, but can we model the relationship between them? For this problem, it's reasonable to use the concept of "Type 3 Fuzzy Set" which doesn't exit up to now, we leave it as an open question for the reader.
   在吃完晚饭的路上，我突然意识到，Type3是一个很难的问题,但我查了一下的确有。我再把上一段修改一下。
   It seems that the bandwidth can also be a Type-2 fuzzy set, and its parameter is the noise level. Can we use the framework of marginal fuzzy set to do this job(i.e. to construct the Type3 fs)? yes we can. now the marginal fuzzy set of the membership u has only one parameter sigma_v, so we can finally cancel out sigma_v if we can model the fuzziness of sigma_v with the noise level as a parameter, we leave it...
   当然还得再补上一句：the fussiness of u depends on the fussiness of the bandwidth, whose fussiness depends on the the noise level, i.e. the Type 3 fuzzy set. It seems feasible to use the framework of marginal fuzzy to （后边接上上一段，哈哈）。
7. 当然我们期望找到噪声程度和sigma_v的关系，这样就可以cancel out sigma_v 了，从而唯一的参数就是从数据中估计出来的noise level啦。
8. 当noise level大的时候，我们得保证一定大的 sigma_v ，使得同一个dense region 中的多个cluster 能够移动到cluster center，同时又不能太大，以防止移动到其他cluster。


#+BEGIN_LaTeX
\bibliographystyle{IEEEtran}
\bibliography{D:/emacs/etc/ZoteroOutput,IEEEabrv}
#+END_LaTeX
